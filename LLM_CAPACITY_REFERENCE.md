# LLM Document Analysis Capacity Reference

## ğŸ“Š Current Configuration

### GPT-4o-mini Specifications
- **Context Window:** 128,000 tokens (~500,000 characters)
- **Input Cost:** $0.150 per 1M tokens
- **Output Cost:** $0.600 per 1M tokens

### Current Limits
```
Per Document:    100,000 characters (~40 pages)
Both Documents:  200,000 characters (~80 pages)
Token Usage:     ~50,000 tokens (only 40% of capacity)
System Prompt:   ~4,000 tokens
Response:        ~4,000 tokens
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total Usage:     ~58,000 / 128,000 tokens (45%)
```

### Cost Per Opportunity
```
Input:   50,000 tokens Ã— $0.150/1M  = $0.0075
Output:   4,000 tokens Ã— $0.600/1M  = $0.0024
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:   ~$0.01 per opportunity analysis
```

---

## ğŸ“„ Document Coverage

| Document Length | Characters | Coverage | Notes |
|----------------|------------|----------|-------|
| 10-20 pages | ~25K-50K | âœ… 100% | Fully analyzed |
| 20-30 pages | ~50K-75K | âœ… 100% | Fully analyzed |
| 30-40 pages | ~75K-100K | âœ… 100% | Fully analyzed |
| 40-50 pages | ~100K-125K | âš ï¸ 80-90% | Main body + most appendixes |
| 50+ pages | ~125K+ | âš ï¸ 70-80% | Main body + some appendixes |

**Assumptions:**
- Average: 2,500 characters per page
- Page varies by font, margins, spacing
- Dense technical docs may have more chars/page

---

## ğŸ”„ What Happens with Long Documents?

### If Document > 100K characters:

1. **First 100K characters analyzed** (main body + initial appendixes)
2. **Truncation note added** to prompt: `[TRUNCATED - DOCUMENT CONTINUES - SOME APPENDIXES MAY BE CUT OFF]`
3. **AI still extracts requirements** from analyzed portion
4. **AI notes appendix references** (e.g., "See Appendix B")
5. **User warned in UI** to verify original documents
6. **Original PDFs linked** prominently for full verification

### Example: 50-Page Document
```
Pages 1-35:  âœ… Fully analyzed (main requirements)
Pages 36-45: âœ… Partially analyzed (appendixes)
Pages 46-50: âŒ Truncated (referenced but not analyzed)

Result: AI extracts main requirements + flags appendixes
User action: Downloads original for appendix details
```

---

## ğŸš€ Future Expansion Options

### If We Need to Handle 100+ Page Documents:

#### Option 1: Increase Limits (Simple)
```typescript
// Could go up to ~200K chars per doc (use 80% of capacity)
const maxLength = 200000;

Pros: âœ… No code changes needed
      âœ… Covers 99% of documents
Cons: âš ï¸ Same cost
      âš ï¸ Very rare documents might still truncate
```

#### Option 2: Chunking Strategy (Complex)
```typescript
// Split each document into chunks, analyze separately
const chunks = splitDocument(text, 100000);
const results = await Promise.all(
  chunks.map(chunk => analyzeChunk(chunk))
);
const merged = mergeResults(results);

Pros: âœ… Handles unlimited length
      âœ… Parallel processing
Cons: âš ï¸ 2-3x cost per opportunity
      âš ï¸ Complex merge logic
      âš ï¸ Potential conflicts in merging
```

#### Option 3: Smart Chunking (Optimal)
```typescript
// Analyze main body + appendixes separately
1. Extract main requirements (first 100K)
2. If truncated, analyze appendixes separately
3. Merge with conflict detection
4. Store combined results

Pros: âœ… Only pays extra for long docs
      âœ… Better appendix coverage
      âœ… Smart about what to chunk
Cons: âš ï¸ More complex logic
      âš ï¸ 2x cost only for long docs
```

---

## ğŸ“ˆ Real-World Usage

### Typical SBIR Instruction Documents

| Component | Typical Length | Coverage |
|-----------|---------------|----------|
| Army | 15-25 pages | âœ… 100% |
| Navy | 20-30 pages | âœ… 100% |
| Air Force | 25-35 pages | âœ… 100% |
| SOCOM | 20-30 pages | âœ… 100% |
| MDA | 15-25 pages | âœ… 100% |

| BAA Document | Typical Length | Coverage |
|--------------|---------------|----------|
| General BAA | 20-40 pages | âœ… 95-100% |
| Phase I | 15-25 pages | âœ… 100% |
| Phase II | 20-35 pages | âœ… 100% |
| Direct Phase II | 25-40 pages | âœ… 95-100% |

**Bottom Line:** Current limits handle 95%+ of documents completely.

---

## ğŸ’° Cost Scaling

### Current: Single Analysis
```
28 active opportunities Ã— $0.01 = $0.28 total
```

### If We Added Chunking (Worst Case)
```
28 active opportunities Ã— $0.02 = $0.56 total
Still incredibly cheap!
```

### Monthly Estimates
```
Assuming ~50 new opportunities per month:

Current approach:    50 Ã— $0.01 = $0.50/month
With chunking:       50 Ã— $0.02 = $1.00/month

Annual: $12-24/year for ALL instruction analysis
```

**Conclusion:** Cost is negligible. Current approach is optimal.

---

## âœ… Recommendations

### Current Settings (100K per doc) are OPTIMAL because:

1. âœ… **Covers 95%+ of documents completely**
2. âœ… **Uses only 40% of available capacity** (room to grow)
3. âœ… **Cost is negligible** (~$0.01 per opportunity)
4. âœ… **Simple implementation** (no chunking complexity)
5. âœ… **Fast** (single API call, ~10-20 seconds)
6. âœ… **Appendix references flagged** (AI notes what's in appendixes)
7. âœ… **Original documents linked** (users verify appendixes)

### Only Change If:
- âŒ Documents regularly exceed 100 pages (RARE)
- âŒ Appendixes are critical and regularly truncated (NOT OBSERVED)
- âŒ Users request more coverage (hasn't happened)

### Monitor:
- ğŸ“Š Check if any documents are being truncated frequently
- ğŸ“Š Track if users report missing requirements
- ğŸ“Š Review if appendixes contain critical requirements (vs just forms/templates)

---

## ğŸ¯ Best Practice

**Current approach is perfect:**

1. AI analyzes main requirements (100% coverage on 95% of docs)
2. AI flags appendix references ("See Appendix B for form")
3. UI prominently links to original documents
4. Users download originals for appendixes/forms
5. Users verify exact formatting from originals

**Result:** 
- âœ… Smart AI guidance for requirements
- âœ… Manual verification for appendixes/forms
- âœ… No transcription errors
- âœ… Low cost
- âœ… Fast performance
- âœ… Best user experience

---

## ğŸ”§ Code Location

To adjust limits if needed:

```typescript
// File: src/lib/llm-instruction-analyzer.ts
// Line: ~207

const maxLength = 100000; // <-- Change this value

// To see full capacity documentation:
// See function comment at line ~73
```

**Don't change unless documents regularly exceed 40 pages!**

